# Reference: https://github.com/DLR-RM/rl-baselines3-zoo/blob/master/hyperparams/ppo.yml#L32
# epoch * n_steps * nenvs: 500×512*8*8
n_timesteps: !!float 163840000
policy: 'MlpPolicy'
n_steps: 64
# mini batch size: num_envs * nsteps / nminibatches 2048×512÷2048
batch_size: 65536
gae_lambda: 0.95
gamma: 0.99
n_epochs: 12
ent_coef: 0.02
# vf_coef: 0.0001
vf_coef: 0.5
learning_rate: !!float 1e-3
clip_range: 0.2
policy_kwargs: "dict(
                  activation_fn=nn.ELU,
                  net_arch=[256, 256,  dict(pi=[256, 128, 64], vf=[256, 128, 64])]
                )"


target_kl: 0.08
# max_grad_norm: 1.0
max_grad_norm: 1.5
seed: 42 # bong

# # Uses VecNormalize class to normalize obs
normalize_input: False
# # Uses VecNormalize class to normalize rew
normalize_value: False
# clip_obs: 5
